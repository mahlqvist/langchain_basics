{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a368ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), \"config\", \".env\")\n",
    "\n",
    "_ = load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key: \n",
    "\traise ValueError(\"API key missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd8fcf",
   "metadata": {},
   "source": [
    "Some key parameters are explained here:\n",
    "- **os.path.join(os.getcwd(), \"config\", \".env\")** constructs the full path to the `.env` file.\n",
    "- **load_dotenv(dotenv_path=env_path)** loads environment variables from the `.env` file at the specified path into the script’s runtime. This allows secure access to sensitive keys.\n",
    "- **os.getenv(\"OPENAI_API_KEY\")** fetches the value of `OPENAI_API_KEY` from the environment variables loaded by load_dotenv. Returns `None` if the key is missing.\n",
    "- **ChatOpenAI()** creates an instance of OpenAI’s chat model via LangChain, configured to interact with the API.\n",
    "\t- `model` specifies the model variant to use.\n",
    "\t- `temperature` controls randomness in responses, from `0` (predictable, deterministic outputs) to `1` (highly creative/random).\n",
    "\t- `top_p` nucleus sampling, which limits token selection to the top 70% (0.7 in this example) of probable options. Works with `temperature` to fine-tune response diversity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f50ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.5,\n",
    "    top_p=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain black holes in one sentence.\"\n",
    "response = llm.invoke(prompt)\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify the following statement as true or false: \n",
    "            'The Eiffel Tower is located in Berlin.'\n",
    "\n",
    "            Answer:\n",
    "\"\"\"\n",
    "response = llm.invoke(prompt)\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "print(f\"Response: {response.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91317390",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question as if you were {role}.\n",
    "QUESTION: {usr_query}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(usr_query=\"Tell me about black holes.\", role=\"Richard Feynman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"role\": \"Richard Feynman\", \"usr_query\": \"Tell me about black holes.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \n",
    "    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \n",
    "    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \n",
    "    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \n",
    "    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Summarize the {content} in one sentence.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "summarize_chain = (\n",
    "    prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "summary = summarize_chain.invoke({\"content\": content})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8259f15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  Greetings, brave adventurer! I am at your service as your Dungeon Master, ready to weave tales of heroism, mystery, and danger. What quest or conundrum shall we embark upon today? Whether you seek guidance on character creation, world-building, or a thrilling encounter, I stand ready to assist. Tell me, what stirs your imagination?\n",
      "\n",
      "AI Message:  Ah, a fellow seeker of adventure! Pray, what question stirs your curiosity in the realms of Dungeons & Dragons? Whether it be the weaving of intricate lore, the crafting of perilous encounters, or the secrets of character mastery, I stand ready to guide you through the mists of imagination. Speak, and let our tale begin!\n",
      "\n",
      "AI Message:  Ah, brave adventurer, the winds of fate have whispered of many paths awaiting your footsteps today. The sun rises over the ancient kingdom of Eldoria, where shadows lengthen and secrets stir beneath the cobblestones. Will you delve into the forgotten catacombs beneath the ruined keep, rumored to be haunted by restless spirits and guarded by cunning traps? Or perhaps the call of the wild beckons you to the Emerald Forest, where elusive fey creatures dance and a mysterious blight threatens the ancient groves?\n",
      "\n",
      "Alternatively, word has reached the bustling market town of Grayhaven of a missing caravan laden with rare artifacts—could it be the work of bandits, or something far more sinister lurking in the nearby hills?\n",
      "\n",
      "Tell me, noble adventurer, what stirs your heart today? Do you seek glory in battle, wisdom in ancient lore, or the thrill of unraveling a dark mystery? Your story begins now—where shall we venture?\n",
      "\n",
      "AI Message:  Ah, a fellow seeker of adventure! I’m ready to weave tales of heroism and mystery for you. What question do you have about the realms of Dungeons & Dragons? Whether it’s about crafting legendary quests, mastering the intricacies of combat, or breathing life into your NPCs, I’m here to guide you through the labyrinth of imagination. Speak, and let our story begin!\n"
     ]
    }
   ],
   "source": [
    "role = \"\"\"\n",
    "    Dungeon & Dragons game master\n",
    "\"\"\"\n",
    "\n",
    "tone = \"engaging and immersive\"\n",
    "\n",
    "template = \"\"\"\n",
    "    You are an expert {role}. I have this question {question}. I would like our conversation to be {tone}.\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "roleplay_chain = (\n",
    "    prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # Get User input\n",
    "    user_message = input(\"\\nUser: \")\n",
    "    \n",
    "    if user_message.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "\n",
    "    # Pass user prompt to generate Response\n",
    "    response = roleplay_chain.invoke({\"role\": role, \"question\": user_message, \"tone\": tone})\n",
    "    \n",
    "    print(\"\\nAI Message: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4ff1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 1\n",
      "\n",
      "- Sentiment: Positive  \n",
      "- Key Features Mentioned: Camera quality, battery life, heating during gaming  \n",
      "- Summary: The reviewer is very satisfied with the smartphone's camera and battery performance, though they note it tends to heat up slightly during gaming.\n",
      "\n",
      "Review: 2\n",
      "\n",
      "- Sentiment: Negative  \n",
      "- Key Features Mentioned: Speed, stability (crashes), keyboard functionality, customer service  \n",
      "- Summary: The laptop performs poorly with slow speed, frequent crashes, a faulty keyboard after two months, and unhelpful customer service.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]\n",
    "\n",
    "template = \"\"\"\n",
    "Analyze the following product review:\n",
    "\"{review}\"\n",
    "\n",
    "Provide your analysis in the following format:\n",
    "- Sentiment: (positive, negative, or neutral)\n",
    "- Key Features Mentioned: (list the product features mentioned)\n",
    "- Summary: (one-sentence summary)\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "#chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "def format_review_prompt(variables):\n",
    "    # The variables parameter expects a dictionary with all template placeholders\n",
    "    # In this case, just {\"review\": \"the actual review text\"}\n",
    "    return prompt.format(**variables)\n",
    "\n",
    "chain = RunnableLambda(format_review_prompt) | llm | StrOutputParser()\n",
    "\n",
    "for i, review in enumerate(reviews):\n",
    "\tres = chain.invoke({\"review\": review})\n",
    "\tprint(f\"Review: {i + 1}\")\n",
    "\tprint(f\"\\n{res}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef0058",
   "metadata": {},
   "source": [
    "#### Basic Chain Approach:\n",
    "\n",
    "```python\n",
    "chain = product_review_prompt | llm | StrOutputParser()\n",
    "```\n",
    "\n",
    "This works perfectly when you have simple variables to pass to the prompt since the prompt template automatically handles the formatting.\n",
    "\n",
    "#### RunnableLambda Approach:\n",
    "\n",
    "```python\n",
    "def format_review_prompt(variables):\n",
    "    # The variables parameter expects a dictionary with all template placeholders\n",
    "    # In this case, just {\"review\": \"the actual review text\"}\n",
    "    return product_review_prompt.format(**variables)\n",
    "\n",
    "chain = RunnableLambda(format_review_prompt) | llm | StrOutputParser()\n",
    "```\n",
    "\n",
    "Use when you need to:\n",
    "  - Preprocess input variables before formatting\n",
    "  - Handle complex input structures\n",
    "  - Add conditional logic to prompt generation\n",
    "\n",
    "If you need to preprocess:\n",
    "\n",
    "```python\n",
    "# If you get input like this:\n",
    "raw_input = \"This product is amazing! The battery lasts forever.\"\n",
    "\n",
    "def format_review_prompt(raw_text):\n",
    "    # Clean the input first\n",
    "    cleaned = raw_text.strip().replace(\"!\", \"\")\n",
    "    return product_review_prompt.format(review=cleaned)\n",
    "```\n",
    "\n",
    "Use your normal `prompt | llm | output_parser` chain for simple cases and only use `RunnableLambda` when you need to:\n",
    "- Transform the input structure\n",
    "- Add preprocessing logic\n",
    "- Handle complex variable mapping\n",
    "\n",
    "In thjs specific example, the `format_review_prompt` function is redundant unless you need to modify the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f613ddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
